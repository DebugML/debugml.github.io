---
title: "CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic Learning"
layout: single
excerpt: "Scaling neurosymbolic learning with program decomposition and tensor sketching."
header:
  overlay_color: "#000"
  overlay_filter: "0.70"
  overlay_image: assets/images/ctsketch/overview-white.png
  teaser: assets/images/ctsketch/overview.png
  actions:
    - label: "Paper"
      url: https://arxiv.org/abs/XXXX.XXXX
    - label: "Code"
      url: https://github.com/alaiasolkobreslin/CTSketch
authors:
  - Seewon Choi|equal
  - Alaia Solko-Breslin|equal
  - Rajeev Alur
  - Eric Wong

scene_recognition:
  - url: /assets/images/ctsketch/scene.png
    image_path: /assets/images/ctsketch/scene.png
    title: Scene recognition can be decomposed as an object detector followed by a call to GPT-4 to classify the scene.

task_decompositions:
  - id: 0
    name: sum
    caption: Program decomposition for MNIST sum of n digits
  - id: 1
    name: add
    caption: Program decomposition for MNIST addition of two n-digit numbers
  - id: 2
    name: visudo
    caption: Program decomposition for Visual Sudoku
  - id: 3
    name: sudoku
    caption: Program decomposition for Sudoku Solving

sketching:
  - id: 0
    name: tt
    caption: Tensor-Train singular value decomposition (TT-SVD)
  - id: 1
    name: tucker
    caption: Tucker decomposition
  - id: 2
    name: cp
    caption: CP (CANDECOMP/PARAFAC) decomposition

---
<style>
.histogram-row {
    display: flex;
    justify-content: space-between;
    flex-wrap: nowrap;
}

.histogram-row > * {
    flex: 0 0 48%; /* this ensures the child takes up 48% of the parent's width (leaving a bit of space between them) */
}

.button-method {
  width: 25%;
  background: rgba(76, 175, 80, 0.0);
  border: 0px;
  border-right: 1px solid #ccc;
  color: #999;
}

.button-sample {
  padding: 5px;
  font-size: 12px;
  background: rgba(76, 175, 80, 0.0);
  display: inline-block;
  margin-right: 15px;
}

.btn-clicked {
  color: black;
}

.container {
  display: flex;
  overflow: auto;
  align-items: center;
}

.container th, .container td {
  text-align: center;
  padding: 1px 5px;
}

.container table {
  width: auto; 
  padding-top:15px;
  margin-right: 5px;
}

.container math, .container div {
  width: auto; 
  margin-right: 15px;
}

.container div {
  margin-left: 15px;
}

.code-block {
  font-size: 14px; /* Adjust the font size as needed */
  text-align: left;
}

.code-snippet {
  display: inline-block;
  margin-left: 15px;
  margin-right: 15px;
}

</style>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.4/Chart.js"></script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>


> This post introduces CTSketch, an algorithm for learning tasks expressed as the composition of neural networks followed by a symbolic program (neurosymbolic learning). 
> CTSketch decomposes the symbolic program using tensor sketches summarizing the input-output pairs of each sub-program and performs fast inference via efficient tensor operations. 
> CTSketch pushes the frontier of neurosymbolic learning, scaling to tasks involving over one thousand inputs, which has never been done before.

Some learning problems benefit from combining neural and symbolic components to improve accuracy and interpretability.
This learning paradigm, called *neurosymbolic learning*, involves the composition of a neural network $M_\theta$ followed by a program $c$, and the goal is to learn with end-to-end labels of the composite.
In our [ISED blog post](https://debugml.github.io/neural-programs/), we introduced a natural decomposition of the scene recognition problem, which involves a neural object detector followed by a program that prompts GPT-4 to classify the scene based on the object predictions.

{% include gallery id="scene_recognition" caption="Scene recognition can be decomposed as an object detector followed by a program that prompts GPT-4 to classify the scene based on the predicted objects." %}

## White- and Black-Box Neurosymbolic Programs

In this last blog post, we define the learning problem in greater detail for learning with black-box programs, whose composite we call *neural programs*.
Black-box neurosymbolic programs are more difficult to study because they can be written in any language, and we don't know the internals of the program (e.g., the GPT-4 call in scene recognition).
This is in contrast to white-box neurosymbolic programs, which usually take the form of differentiable logic programs.

While white-box programs can be easier to learn from, they lack the expressiveness of black-box programs.
For example, in the ISED blog post, we introduced *neuroPython* and *neuroGPT* programs, which are programs in the composed architecture that involve Python programs, and programs that call GPT, respectively.
Such programs can encode complex tasks that can't be represented as logic programs, such as leaf classification and scene recognition using GPT-4.
However, prior work on white- and black-box learning has not been able to scale to tasks involving over one thousand inputs.
This motivates a solution which combines the strengths of both approaches.

## CTSketch

We introduce CTSketch, a novel learning algorithm that can learn with black-box programs and can scale to tasks with large input spaces.
\CTSketch uses two techniques to improve the scalability of neurosymbolic inference: decompose the program into multiple sub-programs and summarize each sub-program with a sketched tensor.
\<br>
We use sum-4, the task of adding four hand-written digits, as the running example.

**Program Decomposition.**
While CTSketch can learn with black-box components, its scalability benefits from program decomposition.
CTSketch works with any manually specified tree structure of sub-programs. 
The sub-programs are evaluated sequentially through the layers of the tree structure, where the first layer of programs corresponds to the leaves and the last sub-program, which predicts the final output, represents the root.Â 
<!--
In the tree structure, the first sub-programs to be evaluated represent the leaves of the tree, while the last sub-program, which predicts the final output, represents the root.
-->
The outputs of the sub-programs further from the root can be fed into sub-programs closer to the root.

As illustrated below, we can decompose sum-4 into a hierarchy of sum-2 operations. 
The architecture consists of a $+$ function (sub-program $c_1$) that adds two numbers between 0-9 and another $+$ function (sub-program $c_2$) that adds two numbers between 0-18.

Click on the thumbnails to see different examples of program decomposition.

<!-- Decomposition Figure -->
<ul class="tab" data-tab="decomposition-examples" data-name="decompexample" style="margin-left:3px">
{% for i in (0..3) %}
<li class="{% if forloop.first %} active{% endif %}" style="width: 15%; padding: 0; margin: 0">
    <a href="#" style="padding: 5%; margin: 0"><img src="/assets/images/ctsketch/blog_figs_attrs/{{ i }}/thumbnail.png" alt="{{ i | plus: 1 }}"></a>
</li>
{% endfor %}
</ul>
<ul class="tab-content" id="decomposition-examples" data-name="decompexample">

{% for example in page.task_decompositions %}
<li class="{% if forloop.first %}active{% endif %}">
    <!-- Masked Images - First Row -->
    <div style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
      {% if forloop.index <= 5 %}
      <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/blog_figs_attrs/{{ example.id }}/{{ example.name }}.png" title="Example {{ forloop.parentloop.index }}" class="image-popup">
              <img src="/assets/images/ctsketch/blog_figs_attrs/{{ example.id }}/{{ example.name }}.png" alt="Masked Image {{ forloop.index }} for {{ forloop.parentloop.index }}" style="width: 95%">
          </a>
          <figcaption>{{ example.caption }}</figcaption>
      </figure>
      {% endif %}
    </div>
</li>
{% endfor %}
</ul>

**Summary Tensor.**
Each sub-program is summarized using a tensor, where each dimension of the tensor summary corresponds to one of the program inputs. For a sub-program $c_i$ that takes $d$ inputs with finite domains, the summary $\phi_i$ is a $d$-dimensional tensor that satisfies $\phi_i[j_1, \dots, j_d] = c_i(j_1, \dots, j_d)$. 

The sum-4 case uses two different tensors $\phi_1: \mathbb{R}^{10 \times 10}$ and $\phi_2: \mathbb{R}^{19 \times 19}$, where for both cases $\phi[a, b] = a + b$. 
With the probability distributions $p_1, \dots, p_4$ predicted by the neural model, inference proceeds by computing $\phi_2(\phi_1(p_1, p_2), \phi_1(p_3, p_4))$.

**Tensor Sketching.**
We use low-rank tensor decomposition methods to reduce the size of the tensor summaries and improve the inference efficiency. 
These techniques find low-rank tensors that reconstruct the original tensor with low error guarantees and exponentially less memory.

See the rank-2 sketches produced by different decomposition methods for the $\phi_1$ in the sum-4 example.
<body style="margin-bottom: 5px">
    <button id="ttbutton" style="background-color: lightgrey" onclick="showTT()">TT</button>
    <button id="tuckerbutton" style="background-color: lightgrey" onclick="showTucker()">Tucker</button> 
    <button id="cpbutton" style="background-color: lightgrey" onclick="showCP()">CP</button> 
      <div id="tt-canvas" style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
      <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/tt.png" title="TT decomposition" class="image-popup">
              <img src="/assets/images/ctsketch/tt.png" alt="TT decomposition" style="width: 95%">
          </a>
          <figcaption>Tensor Train (TT) decomposition. </figcaption>
      </figure>
      </div>
      <div id="tucker-canvas" style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
      <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/tucker.png" title="Tucker decomposition" class="image-popup">
              <img src="/assets/images/ctsketch/tucker.png" alt="Tucker decomposition" style="width: 95%">
          </a>
          <figcaption>Tucker decomposition. </figcaption>
      </figure>
      </div>
      <div id="cp-canvas" style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
      <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/cp.png" title="CP decomposition" class="image-popup">
              <img src="/assets/images/ctsketch/cp.png" alt="CP decomposition" style="width: 95%">
          </a>
          <figcaption>CP (CANDECOMP/PARAFAC) decomposition. </figcaption>
      </figure>
      </div>
    <script>
        function showTT() {
            document.getElementById("tt-canvas").style.display = "flex";
            document.getElementById("tucker-canvas").style.display = "none";
            document.getElementById("cp-canvas").style.display = "none";
        }
        function showTucker() {
            document.getElementById("tt-canvas").style.display = "none";
            document.getElementById("tucker-canvas").style.display = "flex";
            document.getElementById("cp-canvas").style.display = "none";
        }
        function showCP() {
            document.getElementById("tt-canvas").style.display = "none";
            document.getElementById("tucker-canvas").style.display = "none";
            document.getElementById("cp-canvas").style.display = "flex";
        }
        // Show custom table by default
        showTT();
    </script>
</body>


**Algorithm.**
Prior to training, CTSketch initializes each summary tensor $\phi_i$ by sampling a subset of the possible input combinations or enumerating all input combinations.
For each input combination, the entry of corresponding to those inputs is filled with the respective sub-program output.

After initialization, the algorithm uses the TT-SVD decomposition method to obtain sketches.
For the sum-4 task, we apply TT-SVD with the decomposition rank configured to 2, which produces sketches $t_1^1 : \mathbb{R}^{10 \times 2}$ and $t_2^1 : \mathbb{R}^{2 \times 10}$ for $\phi_1$. 
<!--
to produce rank-2 sketches for $\phi_1$ (adds two digits)
Note that TT-SVD guarantees a low reconstruction error, i.e., $\phi_1 \approx t_1^1t_2^1$
-->

Inference proceeds by going layer-by-layer through the program and estimating the expected value of the output. 
We compute the expected value for each sub-program by taking the product of its associated tensor sketches and input distributions.
The expected output for the sum ($\phi_1 \approx t_1^1 \times t_2^1$) of the first two inputs ($p_1$ and $p_2$) is computed as:

$$v = \sum_a^{10} \sum_b^{10} \sum_x^2 p_1[a] p_2[b] t_1^1[a, x] t_2^1[x, b] $$

Then, we apply RBF kernel and $L_1$ normalization to transform the expected value into a distribution. 
For each output value $j$, we use the following formula:

$$p[j] = \text{RBF}(v, j) = \text{exp} \left( -\frac{1}{2\sigma^2}||v - j||_2 \right) $$

The resulting distribution is passed on to the following layers as inputs, and this process repeats until the final layer produces the final output. 

Putting everything together, the entire pipeline for the sum-4 task can be summarized as:
<div id="overview" style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
  <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/overview-white.png" title="CTSketch overview on sum-4" class="image-popup">
              <img src="/assets/images/ctsketch/overview-white.png" alt="CTSketch" style="width: 95%">
          </a>
          <figcaption>CTSketch Overview for sum-4. </figcaption>
  </figure>
</div>

Note that the final output can be directly compared with the ground truth output without undergoing such transformation; 
hence, the final output space of $c$ can be infinite, like floating-point numbers. 

Furthermore, instead of the tensor summaries, we use the symbolic program with the argmax inputs at test time. 

<!-- scales to tasks involving many inputs  -->

## Evaluation
We evaluate CTSketch on the following benchmark tasks: 
<ul>
  <li>sum-$n$: adding $n$ digits ($n \in$ {4, 16, 64, 256, 1024})</li>
  <li>add-$n$: adding two $n$-digit numbers ($n \in$ {1, 2, 4, 15, 100})</li>
  <li>visual Sudoku and Sudoku solving</li>
  <li>Hand-Written Formula (HWF)</li>
  <li>scene recognition and leaf classification (with calls to LLMs) </li>
</ul>
and use Scallop, DeepSoftLog (DSL), IndeCateR, ISED, and A-NeSI as baselines. 

<!--**Performance and Accuracy**-->
<body>
  <!-- 
    <button id="sumButton" style="background-color: lightgrey" onclick="showCustomTable()">Sum-N</button>
    <button id="addButton" style="background-color: lightgrey" onclick="showMnistArithTable()">Add-N</button> 
  -->
    <table id="sumTable" class="styled-table" style="margin-top: 5px;">
        <thead>
            <tr>
                <th></th>
                <th>sum-4</th>
                <th>sum-16</th>
                <th>sum-64</th>
                <th>sum-256</th>
                <th>sum-1024</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <th>Scallop</th>
                <td>88.90</td>
                <td>8.43</td>
                <td>TO</td>
                <td>TO</td>
                <td>TO</td>
            </tr>
            <tr>
                <th>DSL</th>
                <td><strong>94.13</strong></td>
                <td>2.19</td>
                <td>TO</td>
                <td>TO</td>
                <td>TO</td>
            </tr>
            <tr>
                <th>IndeCateR</th>
                <td>92.55</td>
                <td>83.01</td>
                <td>44.43</td>
                <td>0.51</td>
                <td>0.60</td>
            </tr>
            <tr>
                <th>ISED</th>
                <td>90.79</td>
                <td>73.50</td>
                <td>1.50</td>
                <td>0.64</td>
                <td>ERR</td>
            </tr>
            <tr>
                <th>A-NeSI</th>
                <td>93.53</td>
                <td>17.14</td>
                <td>10.39</td>
                <td>0.93</td>
                <td>1.21</td>
            </tr>
            <tr>
                <th>CTSketch</th>
                <td>92.17</td>
                <td><strong>83.84</strong></td>
                <td><strong>47.14</strong></td>
                <td><strong>7.76</strong></td>
                <td><strong>2.73</strong></td>
            </tr>
        </tbody>
    </table>
    <table id="addTable" class="styled-table" style="display:none; margin-top:5px">
        <thead>
            <tr>
                <th></th>
                <th>add-1</th>
                <th>add-2</th>
                <th>add-4</th>
                <th>add-15</th>
                <th>add-100</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <th>Scallop</th>
                <td>96.9</td>
                <td>95.3</td>
                <td>TO</td>
                <td>TO</td>
                <td>TO</td>
            </tr>
            <tr>
                <th>DSL</th>
                <td><strong>98.4</strong></td>
                <td>96.6</td>
                <td><strong>93.5</strong></td>
                <td><strong>77.1</strong></td>
                <td><strong>25.6</strong></td>
            </tr>
            <tr>
                <th>IndeCateR</th>
                <td>97.7</td>
                <td>93.3</td>
                <td>89.0</td>
                <td>69.6</td>
                <td>ERR</td>
            </tr>
            <tr>
                <th>ISED</th>
                <td>91.4</td>
                <td>93.1</td>
                <td>89.7</td>
                <td>0.0</td>
                <td>0.0</td>
            </tr>
            <tr>
                <th>A-NeSI</th>
                <td>97.4</td>
                <td>96.0</td>
                <td>92.1</td>
                <td>76.8</td>
                <td>ERR</td>
            </tr>
            <tr>
                <th>CTSketch</th>
                <td>98.3</td>
                <td><strong>96.7</strong></td>
                <td>92.5</td>
                <td>74.8</td>
                <td>23.5</td>
            </tr>
        </tbody>
    </table>
    <script>
        function showCustomTable() {
            document.getElementById("sumTable").style.display = "table";
            document.getElementById("addTable").style.display = "none";
        }
        function showMnistArithTable() {
            document.getElementById("sumTable").style.display = "none";
            document.getElementById("addTable").style.display = "table";
        }
        function showMnistOtherTable() {
            document.getElementById("sumTable").style.display = "none";
            document.getElementById("addTable").style.display = "none";
        }
        // Show custom table by default
        showCustomTable();
    </script>
</body>

On <em>sum-n</em>, the baseline methods fail to learn sum-256, whereas CTSketch also learns sum-1024, attaining a per-digit accuracy of 93.69%. 
The per-digit accuracy stays at 17.92% for the next best performer A-NeSI.
The baselines struggle due to the weak learning signal from supervising only the final output instead of providing per-digit supervision, as in add-n tasks.

<!--
<canvas id="myChart" style="width:100%;"></canvas>
<script>
  const data = {
    labels: ["add-100", "visudo", "sudoku", "hwf", "scene", "leaf"],
    datasets: [
      {
        label: 'Scallop',
        data: [0.0, 0.0, 0.0, 96.65, 0.0, 0.0], 
        borderColor: "#B85450",
        backgroundColor: "#F8CECC",
        borderWidth: 1,
      },
      {
        label: 'DeepSoftLog',
        data: [25.6, 0.0, 0.0, 0.0, 0.0, 0.0], 
        borderColor: "#e38820",
        backgroundColor: "#ffcf99",
        borderWidth: 1,
      },
      {
        label: 'IndeCateR',
        data: [0.0, 81.92, 66.50, 95.08, 69.16, 12.72],
        borderColor: "#408bcf",
        backgroundColor: "#99c8f2",
        borderWidth: 1,
      },
      {
        label: 'ISED',
        data: [0.0, 50.0, 80.32, 97.34, 79.95, 68.59],
        borderColor: "#9673A6",
        backgroundColor: "#E1D5E7",
        borderWidth: 1,
      },
      {
        label: 'A-NeSI',
        data: [0.0, 92.11, 26.36, 3.13, 72.40, 61.46], 
        borderColor: "#D6B656",
        backgroundColor: "#FFF2CC",
        borderWidth: 1,
      },
      {
        label: 'CTSketch',
        data: [23.5, 92.5, 81.46, 95.22, 74.55, 69.78], 
        borderColor: "#82B366",
        backgroundColor: "#D5E8D4",
        borderWidth: 1,
      },
    ]
  };
  new Chart(document.getElementById("myChart"), {
    type: "bar",
    data: data,
    options: {
      plugins: {
        legend: {
          display: true,
        },
      },
    }
  });
</script>


We evaluate using 11 tasks from the neurosymbolic learning literature. CTSketch is the best performer on 4 of the task, and always comes within 2.55% to the best performer. 
No other baseline performs as consistently well as CTSketch across the tasks. 
Logic-based methods cannot encode tasks involving GPT-4, whereas sampling-based methods struggle as the number of inputs increase. 
Neural approximation methods struggle when the output space if infinite or symbolic component involves compelx reasoning. 
This demonstrate that although designed for scalability, it is still comparable on variety of classic neurosymbolic tasks. 
-->
On the 11 benchmarks from the neurosymbolic learning literature, CTSketch performs consistently well across all tasks. 
This demonstrates that although designed for scalability, CTSketch is still comparable to SOTA methods on classic neurosymbolic tasks.

Moreover, we evaluate the <b>computational efficiency</b> of the techniques by comparing the test accuracy over training time on two tasks, add-15 and add-100. 
CTSketch learns far faster than the baselines as inference only involves efficient tensor multiplications in exchange for less than one minute overhead for initializing the tensor before training. 

<!--
**Computational Efficiency**

<body>
    <button id="button1" style="background-color: lightgrey" onclick="showAdd15()">add-15</button>
    <button id="button2" style="background-color: lightgrey" onclick="showAdd100()">add-100</button> 
    <canvas width="200" height="130" id="add15-canvas">
      {% include blog_ctsketch_time.html %}
    </canvas>
    <canvas width="200" height="130" id="add100-canvas">
      {% include blog_ctsketch_time2.html %}
    </canvas>
    <script>
        function showAdd15() {
            document.getElementById("add15-canvas").style.display = "flex";
            document.getElementById("add100-canvas").style.display = "none";
        }
        function showAdd100() {
            document.getElementById("add15-canvas").style.display = "none";
            document.getElementById("add100-canvas").style.display = "flex";
        }
        // Show custom table by default
        showAdd15();
    </script>
</body>

We compare test accuracy over training time on two tasks: add-15 and add-100. 
On Add-15, CTSketch takes 1.70 seconds, and IndeCateR, A-NeSI, DSL takes 23.07s, 52.72s, and over 20mins respectively.
On Add-100, CTSketch takes 0.92 seconds per epoch, and converges before DSL even finishes one training epoch.
Due to how efficiently if performs inference, CTSketch learns far faster than the baselines.
There is no additional neural network training requried, nor the expensive proof aggregate steps.
On the other hand, CTSketch prepares the tensor before training, with less than one minute overhead, and training only involves efficient tensor multiplication. 
-->


<!--
**Sketching Rank**
<div style="margin-bottom:20px">
<canvas width="200" height="130" id="rank-canvas">
{% include blog_ctsketch_ranking.html %}
</canvas>
</div>


We study how the sketching rank affects accuracy and training time with the HWF task.
We vary the rank for sketching the largest tensor of size $14^7$. 
Comparing the cases of using the original tensor (full-rank) and low-rank approximation, we can see the clear advantage of sketching: when appropriate rank is chosen, CTSketch converges much faster without sacrificng accuracy.
While the rank have to be sufficiently large to learn the optimal weights, the algorithm is not particularly sensitive to the choice of rank, and can be chosen flexibly depending on the available resources.
--> 

## Limitations and Future Work

The primary limitation of CTSketch lies in requiring manual decomposition of the symbolic part to scale to tasks with a large number of inputs. 
As future work, we are interested in automating the decomposition using program synthesis techniques.

Another interesting future direction is exploring different tensor sketching methods and the trade-offs they provide. 
For example, a streaming algorithm would significantly reduce memory usage with a small time overhead while initializing tensor sketches.

## Conclusion
We proposed CTSketch, a framework that uses decomposed programs to scale neurosymbolic learning. 
CTSketch uses sketched tensors representing the summary of each sub-program to efficiently approximate the output distribution of the symbolic component using simple tensor operations. 
We demonstrate that CTSketch pushes the frontier of neurosymbolic learning, solving significantly larger problems than prior works could solve while remaining competitive with existing techniques on standard neurosymbolic learning benchmarks.

For more details about our method and experiments, see our [paper](https://arxiv.org/abs/) and [code](https://github.com/alaiasolkobreslin/CTSketch).


### Citation
```
@article{choi2025CTSketch,
  title={CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic Learning},
  author={Choi, Seewon and Solko-Breslin, Alaia and Alur, Rajeev and Wong, Eric},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2025}
}
```