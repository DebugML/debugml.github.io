---
title: "CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic Learning"
layout: single
excerpt: "Scaling neurosymbolic learning with program decomposition and tensor sketching."
header:
  overlay_color: "#000"
  overlay_filter: "0.70"
  overlay_image: assets/images/ctsketch/overview-white.png
  teaser: assets/images/ctsketch/overview.png
  actions:
    - label: "Paper"
      url: https://arxiv.org/abs/XXXX.XXXX
    - label: "Code"
      url: https://github.com/alaiasolkobreslin/CTSketch
authors:
  - Seewon Choi|equal
  - Alaia Solko-Breslin|equal
  - Rajeev Alur
  - Eric Wong

scene_recognition:
  - url: /assets/images/ctsketch/scene.png
    image_path: /assets/images/ctsketch/scene.png
    title: Scene recognition can be decomposed as an object detector followed by a call to GPT-4 to classify the scene.

task_decompositions:
  - id: 0
    name: sum
    caption: Program decomposition for MNIST sum of n digits
  - id: 1
    name: add
    caption: Program decomposition for MNIST addition of two n-digit numbers
  - id: 2
    name: visudo
    caption: Program decomposition for Visual Sudoku
  - id: 3
    name: sudoku
    caption: Program decomposition for Sudoku Solving

sketching:
  - id: 0
    name: tt
    caption: Tensor-Train singular value decomposition (TT-SVD)
  - id: 1
    name: tucker
    caption: Tucker decomposition
  - id: 2
    name: cp
    caption: CP (CANDECOMP/PARAFAC) decomposition

---
<style>
.histogram-row {
    display: flex;
    justify-content: space-between;
    flex-wrap: nowrap;
}

.histogram-row > * {
    flex: 0 0 48%; /* this ensures the child takes up 48% of the parent's width (leaving a bit of space between them) */
}

.button-method {
  width: 25%;
  background: rgba(76, 175, 80, 0.0);
  border: 0px;
  border-right: 1px solid #ccc;
  color: #999;
}

.button-sample {
  padding: 5px;
  font-size: 12px;
  background: rgba(76, 175, 80, 0.0);
  display: inline-block;
  margin-right: 15px;
}

.btn-clicked {
  color: black;
}

.container {
  display: flex;
  overflow: auto;
  align-items: center;
}

.container th, .container td {
  text-align: center;
  padding: 1px 5px;
}

.container table {
  width: auto; 
  padding-top:15px;
  margin-right: 5px;
}

.container math, .container div {
  width: auto; 
  margin-right: 15px;
}

.container div {
  margin-left: 15px;
}

.code-block {
  font-size: 14px; /* Adjust the font size as needed */
  text-align: left;
}

.code-snippet {
  display: inline-block;
  margin-left: 15px;
  margin-right: 15px;
}

</style>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.4/Chart.js"></script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>


> This post introduces CTSketch, an algorithm for learning tasks expressed as the composition of a neural network followed by a symbolic program (neurosymbolic learning). 
> CTSketch decomposes the symbolic program using sketched tensors that summarize the input-output pairs of each sub-program and performs fast inference via simple tensor operations. 
> CTSketch pushes the frontier of neurosymbolic learning, scaling to tasks involving 1,024 inputs, which has never been studied before. 

Neurosymbolic programs are the composition of a neural network $M_\theta$ followed by a fixed symbolic program $c$.
The challenge of neurosymbolic learning concerns learning $M_\theta$ without intermediate labels.
Concretely, given an input example $(x, y)$, symbolic program $c$, and loss function $L$, we must predict the distribution for the output ${y'} = c(M_{\theta}(x))$ while ensuring that the loss $L({y'}, y)$ is fully differentiable.
We now discuss prior works on neurosymbolic learning, which provide different techniques for estimating the output distribution of the composite.

## White- and Black-Box Neurosymbolic Frameworks

Existing neurosymbolic learning techniques are usually categorized as either white- or black-box. 
White-box techniques allow access to the internals of the symbolic program in order to compute and output probability distribution from the input distributions.
Differentiable logic programming frameworks are one form of white-box learning technique. 
These frameworks require the symbolic component to be written in a logic programming language like probabilistic Prolog (as in [DeepProbLog](https://arxiv.org/abs/1805.10872)) or Datalog (as in [Scallop](https://arxiv.org/abs/2304.04812)).
These techniques offer heuristics for computing an output probability distribution that is a function of the input distributions predicted by the neural network.
This is what allows the loss to be fully differentiable with respect to the input distributions.


On the other hand, black-box frameworks assume no access to the internals of the symbolic component.
[IndeCateR](https://arxiv.org/abs/2311.12569) and [ISED](https://arxiv.org/abs/2406.06246) are frameworks that sample inputs to the symbolic program and reward inputs that result in the correct output.
[A-NeSI](https://arxiv.org/abs/2212.12393) is an algorithm for approximating the output distribution of the composite with a neural network.

Because these techniques are suited for black-box programs, the symbolic component can be written in any programming language. 
This means that the symbolic component can even use a large language model (LLM) like GPT-4 to perform reasoning over the predictions from the network. 
For example, scene recognition has a natural decomposition of an object detector followed by a program that prompts GPT-4 to classify the scene based on these objects.

{% include gallery id="scene_recognition" caption="Scene recognition can be decomposed as an object detector followed by a program that prompts GPT-4 to classify the scene based on the predicted objects." %}

## CTSketch

We introduce CTSketch, a novel framework that combines the strengths of white- and black-box techniques.
CTSketch uses two techniques to improve the scalability of neurosymbolic inference: decompose the program into multiple sub-programs and summarize each sub-program with a sketched tensor. <br>
We use sum-4, the task of adding four hand-written digits, as the running example. 

**Program Decomposition.**
While CTSketch can learn black-box programs, its scalability benefits from program decomposition. We can manually specify sub-programs that form a tree structure with $m$ layers.
The idea of decomposing the program is that the program can be evaluated sequentially through the sub-program layers.
In the tree structure, the first sub-programs to be evaluated represent the leaves of the tree, while the last sub-program, which predicts the final output, represents the root.
In this model, outputs of sub-programs that are further from the root of the tree can be fed into sub-programs that are closer to the root.

As illustrated below, we can decompose sum-4 into a hierarchy of sum-2 operations.
The architecture suggests that there is a + function (which we call $\phi_1$) that adds two numbers between 0-9 and a + function (which we call $\phi_2$) that adds two numbers between 0-18.
With input probability distributions $p_1$, $p_2$, $p_3$, $p_4$, inference proceeds by computing $\phi_2(\phi_1(p_1, p_2), \phi_1(p_3, p_4))$.

Click on the thumbnails to see different examples of program decomposition.

<!-- Decomposition Figure -->
<ul class="tab" data-tab="decomposition-examples" data-name="decompexample" style="margin-left:3px">
{% for i in (0..3) %}
<li class="{% if forloop.first %} active{% endif %}" style="width: 15%; height: 50px; padding: 0; margin: 0">
    <a href="#" style="padding: 5%; margin: 0"><img src="/assets/images/ctsketch/blog_figs_attrs/{{ i }}/thumbnail.png" alt="{{ i | plus: 1 }}"></a>
</li>
{% endfor %}
</ul>
<ul class="tab-content" id="decomposition-examples" data-name="decompexample">

{% for example in page.task_decompositions %}
<li class="{% if forloop.first %}active{% endif %}">
    <!-- Masked Images - First Row -->
    <div style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
      {% if forloop.index <= 5 %}
      <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/blog_figs_attrs/{{ example.id }}/{{ example.name }}.png" title="Example {{ forloop.parentloop.index }}" class="image-popup">
              <img src="/assets/images/ctsketch/blog_figs_attrs/{{ example.id }}/{{ example.name }}.png" alt="Masked Image {{ forloop.index }} for {{ forloop.parentloop.index }}" style="width: 95%">
          </a>
          <figcaption>{{ example.caption }}</figcaption>
      </figure>
      {% endif %}
    </div>
</li>
{% endfor %}
</ul>

**Sumamry Tensor.**
Each sub-program is summarized using a tensor, where each dimension of the tensor summary corresponds to one of the discrete program inputs. For a sub-program $c_i$ that takes $d$ inputs, the summary $\phi_i$ will be a $d$-dimensional tensor that satisfies $\phi_i[j_1, \dots, j_d] = c(j_1, \dots, j_d)$. 

The sum-4 case will use two different tensors $\phi_1: \mathbb{R}^{10 \times 10}$ and $\phi_2: \mathbb{R}^{19 \times 19}$, where for both cases $\phi[i, j] = i + j$. 


**Tensor Sketching.**
We use low-rank tensor decomposition methods to reduce the size of the tensor summaries and increase the efficiency of inference. These techniques find low-rank tensors that reconstruct the original tensor with low error and exponentially less memory.

See the rank-2 sketches produced by different decomposition methods for the $\phi_1$ in the sum-4 example:
<body style="margin-bottom: 5px">
    <button id="ttbutton" style="background-color: lightgrey" onclick="showTT()">TT</button>
    <button id="tuckerbutton" style="background-color: lightgrey" onclick="showTucker()">Tucker</button> 
    <button id="cpbutton" style="background-color: lightgrey" onclick="showCP()">CP</button> 
      <div id="tt-canvas" style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
      <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/tt.png" title="TT decomposition" class="image-popup">
              <img src="/assets/images/ctsketch/tt.png" alt="TT decomposition" style="width: 95%">
          </a>
          <figcaption>Tensor Train (TT) decomposition</figcaption>
      </figure>
      </div>
      <div id="tucker-canvas" style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
      <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/tucker.png" title="Tucker decomposition" class="image-popup">
              <img src="/assets/images/ctsketch/tucker.png" alt="Tucker decomposition" style="width: 95%">
          </a>
          <figcaption>Tucker decomposition</figcaption>
      </figure>
      </div>
      <div id="cp-canvas" style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
      <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/cp.png" title="CP decomposition" class="image-popup">
              <img src="/assets/images/ctsketch/cp.png" alt="CP decomposition" style="width: 95%">
          </a>
          <figcaption>CP (CANDECOMP/PARAFAC) decomposition</figcaption>
      </figure>
      </div>
    <script>
        function showTT() {
            document.getElementById("tt-canvas").style.display = "flex";
            document.getElementById("tucker-canvas").style.display = "none";
            document.getElementById("cp-canvas").style.display = "none";
        }
        function showTucker() {
            document.getElementById("tt-canvas").style.display = "none";
            document.getElementById("tucker-canvas").style.display = "flex";
            document.getElementById("cp-canvas").style.display = "none";
        }
        function showCP() {
            document.getElementById("tt-canvas").style.display = "none";
            document.getElementById("tucker-canvas").style.display = "none";
            document.getElementById("cp-canvas").style.display = "flex";
        }
        // Show custom table by default
        showTT();
    </script>
</body>


**Algorithm.**
Prior to training, CTSketch initializes each summary tensor $\phi_i$ by sampling a subset of the possible input combinations or enumerating all input combinations.
For each input combination, the index of $\phi_i$ corresponding to those inputs is initialized with their corresponding sub-program output.

After initialization, the algorithm uses the TT-SVD decomposition method to obtain sketches.
For the sum-4 example, if we require TT-SVD to produce rank-2 tensors for $\phi_1$ (adds two digits), then the algorithm will output $t_1^1 : \mathbb{R}^{10 \times 2}$ and $t_2^1 : \mathbb{R}^{2 \times 10}$.
Note that TT-SVD guarantees a low reconstruction error, i.e., $\phi_1 \approx t_1^1t_2^1$

Inference proceeds by going layer-by-layer through the program and estimating the expected value of the output. This computation is done sequentially from layers 1 to $m$, whereas computations within a layer can run in parallel. 

We compute the expected value for each sub-program by taking the product of its associated tensor sketches and input distributions.
The output for the sum of the first two inputs would be computed as:

$$v = \sum_a^{10} \sum_b^{10} \sum_x^2 p_1[a] p_2[b] t_1^1[a, x] t_2^1[x, b] $$

Then, we apply RBF kernel and L1 normalization to transform the expected value into a distribution. For output value $j$, we use the following formula:

$$p[j] = \text{RBF}(v, j) = \text{exp} \left( -\frac{1}{2\sigma^2}||v - j||_2 \right) $$

The resulting distribution is passed on to the following layers as inputs, and this process repeats until the final layer produces the final output. 

Putting everything together, the entire pipeline for the sum-4 task can be summarized as:
<div id="overview" style="text-align: center; display: flex; justify-content: space-around; align-items: center;">
  <figure class="center" style="margin: 0;">
          <a href="/assets/images/ctsketch/overview-white.png" title="CTSketch overview on sum-4" class="image-popup">
              <img src="/assets/images/ctsketch/overview-white.png" alt="CTSketch" style="width: 95%">
          </a>
          <figcaption>CTSketch Overview for sum-4</figcaption>
  </figure>
</div>

Note that the final output can be directly compared with the ground truth output without undergoing such transformation; hence, the final output space of $c$ can be infinite, like floating-point numbers. 

Furthermore, instead of tensor sketches, we use the symbolic program with the argmax inputs at test time. 

<!-- scales to tasks involving many inputs  -->

## Evaluation
We evaluate CTSketch on the following benchmark tasks: 
<ul>
  <li>sum-$n$: adding $n$ digits ($n \in$ {4, 16, 64, 256, 1024})
  <li>add-$n$: adding two $n$-digit numbers ($n \in$ {1, 2, 4, 15, 100})
  <li>visual Sudoku and Sudoku solving</li>
  <li>Hand-Written Formula (HWF)</li>
  <li>scene recognition and leaf classification (with calls to LLMs) </li>
</ul>
and use Scallop, DeepSoftLog (DSL), IndeCateR, ISED, and A-NeSI as baselines. 

**Performance and Accuracy**
<body>
  <!-- 
    <button id="sumButton" style="background-color: lightgrey" onclick="showCustomTable()">Sum-N</button>
    <button id="addButton" style="background-color: lightgrey" onclick="showMnistArithTable()">Add-N</button> 
  -->
    <table id="sumTable" class="styled-table" style="margin-top: 5px;">
        <thead>
            <tr>
                <th></th>
                <th>sum-4</th>
                <th>sum-16</th>
                <th>sum-64</th>
                <th>sum-256</th>
                <th>sum-1024</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <th>Scallop</th>
                <td>88.90</td>
                <td>8.43</td>
                <td>TO</td>
                <td>TO</td>
                <td>TO</td>
            </tr>
            <tr>
                <th>DSL</th>
                <td><strong>94.13</strong></td>
                <td>2.19</td>
                <td>TO</td>
                <td>TO</td>
                <td>TO</td>
            </tr>
            <tr>
                <th>IndeCateR</th>
                <td>92.55</td>
                <td>83.01</td>
                <td>44.43</td>
                <td>0.51</td>
                <td>0.60</td>
            </tr>
            <tr>
                <th>ISED</th>
                <td>90.79</td>
                <td>73.50</td>
                <td>1.50</td>
                <td>0.64</td>
                <td>ERR</td>
            </tr>
            <tr>
                <th>A-NeSI</th>
                <td>93.53</td>
                <td>17.14</td>
                <td>10.39</td>
                <td>0.93</td>
                <td>1.21</td>
            </tr>
            <tr>
                <th>CTSketch</th>
                <td>92.17</td>
                <td><strong>83.84</strong></td>
                <td><strong>47.14</strong></td>
                <td><strong>7.76</strong></td>
                <td><strong>2.73</strong></td>
            </tr>
        </tbody>
    </table>
    <table id="addTable" class="styled-table" style="display:none; margin-top:5px">
        <thead>
            <tr>
                <th></th>
                <th>add-1</th>
                <th>add-2</th>
                <th>add-4</th>
                <th>add-15</th>
                <th>add-100</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <th>Scallop</th>
                <td>96.9</td>
                <td>95.3</td>
                <td>TO</td>
                <td>TO</td>
                <td>TO</td>
            </tr>
            <tr>
                <th>DSL</th>
                <td><strong>98.4</strong></td>
                <td>96.6</td>
                <td><strong>93.5</strong></td>
                <td><strong>77.1</strong></td>
                <td><strong>25.6</strong></td>
            </tr>
            <tr>
                <th>IndeCateR</th>
                <td>97.7</td>
                <td>93.3</td>
                <td>89.0</td>
                <td>69.6</td>
                <td>ERR</td>
            </tr>
            <tr>
                <th>ISED</th>
                <td>91.4</td>
                <td>93.1</td>
                <td>89.7</td>
                <td>0.0</td>
                <td>0.0</td>
            </tr>
            <tr>
                <th>A-NeSI</th>
                <td>97.4</td>
                <td>96.0</td>
                <td>92.1</td>
                <td>76.8</td>
                <td>ERR</td>
            </tr>
            <tr>
                <th>CTSketch</th>
                <td>98.3</td>
                <td><strong>96.7</strong></td>
                <td>92.5</td>
                <td>74.8</td>
                <td>23.5</td>
            </tr>
        </tbody>
    </table>
    <script>
        function showCustomTable() {
            document.getElementById("sumTable").style.display = "table";
            document.getElementById("addTable").style.display = "none";
        }
        function showMnistArithTable() {
            document.getElementById("sumTable").style.display = "none";
            document.getElementById("addTable").style.display = "table";
        }
        function showMnistOtherTable() {
            document.getElementById("sumTable").style.display = "none";
            document.getElementById("addTable").style.display = "none";
        }
        // Show custom table by default
        showCustomTable();
    </script>
</body>

The baseline methods fail to learn sum-256, whereas CTSketch also learns sum-1024, attaining a per-digit accuracy of 93.69%. 
The per-digit accuracy stays at 17.92% for the next best performer A-NeSI.
Compared to the add−n task, where per-digit supervision is provided, the supervision is only on the final output, and many methods fail due to the weak learning signal.

<!--
<canvas id="myChart" style="width:100%;"></canvas>
<script>
  const data = {
    labels: ["add-100", "visudo", "sudoku", "hwf", "scene", "leaf"],
    datasets: [
      {
        label: 'Scallop',
        data: [0.0, 0.0, 0.0, 96.65, 0.0, 0.0], 
        borderColor: "#B85450",
        backgroundColor: "#F8CECC",
        borderWidth: 1,
      },
      {
        label: 'DeepSoftLog',
        data: [25.6, 0.0, 0.0, 0.0, 0.0, 0.0], 
        borderColor: "#e38820",
        backgroundColor: "#ffcf99",
        borderWidth: 1,
      },
      {
        label: 'IndeCateR',
        data: [0.0, 81.92, 66.50, 95.08, 69.16, 12.72],
        borderColor: "#408bcf",
        backgroundColor: "#99c8f2",
        borderWidth: 1,
      },
      {
        label: 'ISED',
        data: [0.0, 50.0, 80.32, 97.34, 79.95, 68.59],
        borderColor: "#9673A6",
        backgroundColor: "#E1D5E7",
        borderWidth: 1,
      },
      {
        label: 'A-NeSI',
        data: [0.0, 92.11, 26.36, 3.13, 72.40, 61.46], 
        borderColor: "#D6B656",
        backgroundColor: "#FFF2CC",
        borderWidth: 1,
      },
      {
        label: 'CTSketch',
        data: [23.5, 92.5, 81.46, 95.22, 74.55, 69.78], 
        borderColor: "#82B366",
        backgroundColor: "#D5E8D4",
        borderWidth: 1,
      },
    ]
  };
  new Chart(document.getElementById("myChart"), {
    type: "bar",
    data: data,
    options: {
      plugins: {
        legend: {
          display: true,
        },
      },
    }
  });
</script>


We evaluate using 11 tasks from the neurosymbolic learning literature. CTSketch is the best performer on 4 of the task, and always comes within 2.55% to the best performer. 
No other baseline performs as consistently well as CTSketch across the tasks. 
Logic-based methods cannot encode tasks involving GPT-4, whereas sampling-based methods struggle as the number of inputs increase. 
Neural approximation methods struggle when the output space if infinite or symbolic component involves compelx reasoning. 
This demonstrate that although designed for scalability, it is still comparable on variety of classic neurosymbolic tasks. 
-->
On the 11 tasks from the neurosymbolic learning literature, CTSketch performs consistently well across all tasks. This demonstrates that although designed for scalability, CTSketch is still comparable to classic neurosymbolic tasks.

**Computational Efficiency**

We compare test accuracy over training time of all methods on two tasks, add-15 and add-100. 
CTSketch learns far faster than the baselines as inference only involves efficient tensor multiplications with less than one minute overhead for initializing the tensor before training. 

<!--
<body>
    <button id="button1" style="background-color: lightgrey" onclick="showAdd15()">add-15</button>
    <button id="button2" style="background-color: lightgrey" onclick="showAdd100()">add-100</button> 
    <canvas width="200" height="130" id="add15-canvas">
      {% include blog_ctsketch_time.html %}
    </canvas>
    <canvas width="200" height="130" id="add100-canvas">
      {% include blog_ctsketch_time2.html %}
    </canvas>
    <script>
        function showAdd15() {
            document.getElementById("add15-canvas").style.display = "flex";
            document.getElementById("add100-canvas").style.display = "none";
        }
        function showAdd100() {
            document.getElementById("add15-canvas").style.display = "none";
            document.getElementById("add100-canvas").style.display = "flex";
        }
        // Show custom table by default
        showAdd15();
    </script>
</body>

We compare test accuracy over training time on two tasks: add-15 and add-100. 
On Add-15, CTSketch takes 1.70 seconds, and IndeCateR, A-NeSI, DSL takes 23.07s, 52.72s, and over 20mins respectively.
On Add-100, CTSketch takes 0.92 seconds per epoch, and converges before DSL even finishes one training epoch.
Due to how efficiently if performs inference, CTSketch learns far faster than the baselines.
There is no additional neural network training requried, nor the expensive proof aggregate steps.
On the other hand, CTSketch prepares the tensor before training, with less than one minute overhead, and training only involves efficient tensor multiplication. 
-->


<!--
**Sketching Rank**
<div style="margin-bottom:20px">
<canvas width="200" height="130" id="rank-canvas">
{% include blog_ctsketch_ranking.html %}
</canvas>
</div>


We study how the sketching rank affects accuracy and training time with the HWF task.
We vary the rank for sketching the largest tensor of size $14^7$. 
Comparing the cases of using the original tensor (full-rank) and low-rank approximation, we can see the clear advantage of sketching: when appropriate rank is chosen, CTSketch converges much faster without sacrificng accuracy.
While the rank have to be sufficiently large to learn the optimal weights, the algorithm is not particularly sensitive to the choice of rank, and can be chosen flexibly depending on the available resources.
--> 

## Limitations and Future Work

The primary limitation of CTSketch lies in requiring manual decomposition of the symbolic part to scale to tasks with a large number of inputs. 
We are interested in automating the decomposition using program synthesis techniques for future work.

Another interesting future direction is exploring different tensor sketching methods and the trade-offs they provide. For example, if we use a streaming algorithm, we would significantly reduce memory usage with a small time overhead when initializing the tensor sketches.

## Conclusion
We proposed CTSketch, a framework that uses decomposed programs to scale neurosymbolic learning. 
CTSketch uses sketched tensors representing the summary of each sub-program to efficiently approximate the output distribution of the symbolic component using simple tensor operations. 
We demonstrate that CTSketch pushes the frontier of neurosymbolic learning, solving significantly larger problems than prior works could solve while remaining competitive with existing techniques on standard neurosymbolic learning benchmarks.

For more details about our method and experiments, see our [paper](https://arxiv.org/abs/) and [code](https://github.com/alaiasolkobreslin/CTSketch).


### Citation
```
@article{choi2025CTSketch,
  title={CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic Learning},
  author={Choi, Seewon and Solko-Breslin, Alaia and Alur, Rajeev and Wong, Eric},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2025}
}
```