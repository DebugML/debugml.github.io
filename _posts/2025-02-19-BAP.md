---
published: true
title:  "Where’s the Bug? Attention Probing for Scalable Fault Localization"
excerpt: "A performant, lightweight approach to identifying line-level bugs with only weak supervision."
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: assets/images/BAP/bap_fig1.png
  teaser: assets/images/BAP/bap_fig1.png
  actions:
    - label: "Paper"
      url: "https://arxiv.org/abs/2502.13966"
    - label: "Code"
      url: "https://github.com/adaminsky/BAP" 
authors:
  - Adam Stein|equal
  - Arthur Wayne|equal
  - Aaditya Naik
  - Mayur Naik
  - Eric Wong

---

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script src="https://cdn.jsdelivr.net/npm/chart.js@3.7"></script>
<script src="https://cdn.jsdelivr.net/npm/chartjs-chart-matrix@1.1"></script>
<script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>

Pinpointing the precise location of bugs in code, also known as fault localization (FL), is a central challenge for AI-powered software engineering. As large language models (LLMs) grow increasingly performant for code-related tasks, this issue has become more pressing than ever. LLM-based automatic can propose bug fixes using only a user’s bug report, but their effectiveness is <i>fundamentally limited</i> by their ability to perform fault localization.

Existing deep learning-based FL techniques either:  
1. **Demand Execution:** Require running tests (e.g., spectrum-based or mutation-based)  
2. **Require Strong Supervision:** Need large datasets of line-level bug labels  
3. **Rely on Large LLMs:** Perform only somewhat reliably and extremely expensive at scale

For large, real-world, and rapidly evolving codebases, these solutions are not scalable. The leads us to a central question: *How do we achieve strong FL performance without tests, strong supervision, or large-scale models?*

To this end, we propose the **Bug Attention Probe (BAP)** which tackles FL by learning to localize bugs with only *weak supervision*—that is, without needing explicit localization labels. BAP outperforms traditional FL baselines and prompting of large-scale LLMs

---

## Highlights of BAP

1. **Lightweight, Yet Powerful**
    BAP is significantly more efficient than prompting, outperforming large open-weight models at a small fraction of the computational cost. Even a 1B parameter base model with BAP outperforms zero-shot prompts on 90B parameter models <i>and</i> GPT-4o.

2. **Multi-line Bug Localization**  
   Because our method produces a ranking for each line of code in a given snippet, multiple suspicious lines can be identified simultaneously.

3. **Stronger Generalization**  
   BAP performs well on new, unseen bugs (e.g., Defects4J v3.0.1) even when trained on older or smaller sets.

---

### Key Idea
BAP is built around the insight that a model's attention mechanism can implicitly reveal the most suspicious parts of code. If we train a small model to classify code as buggy or not (weak supervision), its learned attention weights may reveal which tokens lead to that decision. Summing those attention patterns at the line level produces a human-interpretable localization—no explicit line-level bug label needed.

**Steps**:
1. **Weak Supervision**  
   BAP trains on a bug detection dataset: each sample is labeled just “buggy” or “clean.” No line-level info needed.  
2. **Attention Extraction**  
   We attach a single-layer Transformer decoder block (a probe) to the LLM’s hidden states. As we train on the detection task, we collect each token’s attention score to the final token.  
3. **Line-level Ranking**  
   We sum the attention of tokens belonging to each line. The line(s) with the highest sum is flagged as most likely containing the bug.

---

## A Toy Buggy Example
Considering the following Java program:
```java
Integer vote;
public void addVote(int age) {
  if (age >= 18) {
    System.out.println("You're a minor!");
  } else {
    vote++;
    System.out.println("You can vote!");
  }
}
```
**What went wrong?**  
The condition is inverted (`>= 18` prints “You’re a minor!”), and `vote` can be null.  

<!-- BEGIN HIGHLIGHTED CODE SNIPPET -->
<style>
.code-container {
    font-family: monospace;
    font-size: 10px;
    white-space: pre-wrap;
    padding: 5px;
    background-color: #f5f5f5;
    border-radius: 3px;
    width: 500px;
    border: 1px solid #ddd;
}
.line-container {
    display: flex;
    align-items: flex-start;
}
.score {
    width: 30px;
    text-align: right;
    padding-right: 5px;
    color: #666;
    font-weight: bold;
    font-size: 10px;
}
.code {
    flex: 1;
    padding-left: 3px;
    transition: background-color 0.2s, color 0.2s;
}
.buggy:hover {
    background-color: rgba(255, 0, 0, 0.4) !important;
    color: white;
    cursor: pointer;
}
</style>

<div class='code-container'>

<div class='line-container'><span class='score'>0.03</span><span class='code' style='background-color: rgba(0, 204, 102, 0.05);'>Integer vote;</span></div>
<div class='line-container'><span class='score'>0.07</span><span class='code' style='background-color: rgba(0, 204, 102, 0.10);'>public void addVote(int age) {</span></div>
<div class='line-container'><span class='score' style='color: red'>0.28</span><span class='code buggy' style='background-color: rgba(0, 204, 102, 0.66666666);'>    if (age >= 18) {</span></div>
<div class='line-container'><span class='score'>0.05</span><span class='code' style='background-color: rgba(0, 204, 102, 0.03);'>        System.out.println("You're a minor!");</span></div>
<div class='line-container'><span class='score'>0.04</span><span class='code' style='background-color: rgba(0, 204, 102, 0.02);'>    } else {</span></div>
<div class='line-container'><span class='score' style='color: red'>0.28</span><span class='code buggy' style='background-color: rgba(0, 204, 102, 0.66666666);'>        vote++;</span></div>
<div class='line-container'><span class='score'>0.10</span><span class='code' style='background-color: rgba(0, 204, 102, 0.15);'>        System.out.println("You can vote!");</span></div>
<div class='line-container'><span class='score'>0.02</span><span class='code' style='background-color: rgba(0, 204, 102, 0.0);'>    }</span></div>
<div class='line-container'><span class='score'>0.01</span><span class='code' style='background-color: rgba(0, 204, 102, 0.0);'>}</span></div>

</div>
<!-- END HIGHLIGHTED CODE SNIPPET -->
**What BAP sees**  
After training on just “buggy” vs “clean,” BAP’s line-level attention highlights `if (age >= 18)` and `vote++;` as top suspects for buggy lines. No test harness or line-level annotations were needed—only knowledge that “this snippet is buggy.”

In reality, the bugs we evaluate on are far less clear cut and better resemble real-world bug encounters.

---

## Performance Snapshot

BAP was evaluated against baselines across eight diverse datasets, spanning a variety of languages and bug types, including:  
   - [Defects4J v1.2.0](https://github.com/rjust/defects4j) (395 real-world Java bugs) and [Defects4J v3.0.1](https://github.com/rjust/defects4j) (543 additional bugs, released November 2024)  
   - [GitHub-Python](https://nlp.stanford.edu/pubs/pybugs.pdf) (syntax errors, Yasunaga & Liang, 2021) and [GitHub-Java](https://arxiv.org/abs/1809.03068) (syntax errors, Santos et al., 2018)  
   - [DeepFix](https://arxiv.org/abs/1705.07852) (real C programs written by students, Gupta et al., 2017)  
   - [TSSB-3M](https://arxiv.org/abs/2209.00722) (“Simple, stupid bugs” in Python, Richter & Wehrheim, 2022)  
   - [ManySStuBs4J](https://arxiv.org/abs/2005.10636) (Java SStuBs, Karampatsis & Sutton, 2020)  
   - [Juliet-Java](https://samate.nist.gov/SARD/test-suites/112) and [Juliet-C](https://samate.nist.gov/SARD/test-suites/111) (synthetic code with Common Weakness Enumerations, NIST Juliet Test Suite, 2023)  

<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>All Charts Example</title>
  <!-- Load Chart.js only once -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>

<!-- 1) TOP-1 LOCALIZATION ACCURACY -->
<h2>Top-1 Localization Accuracy</h2>
<p>
  Averaged across all eight datasets, BAP improves by 34.6% top-1 accuracy
  compared to the strongest baseline and 93.4% over zero-shot prompting GPT-4.
</p>

<canvas id="comparisonChart" width="800" height="600"></canvas>
<script>
  const ctx1 = document.getElementById('comparisonChart').getContext('2d');

  const data1 = {
    labels: ['D4J', 'GH-Py', 'GH-J', 'DeepFix', 'TSSB', 'MS4J', 'Juliet-J', 'Juliet-C', 'Avg.'],
    datasets: [
      {
        label: 'BAP',
        data: [0.334, 0.575, 0.568, 0.481, 0.327, 0.291, 0.096, 0.217, 0.350],
        backgroundColor: 'darkblue'
      },
      {
        label: 'LLMAO',
        data: [0.144, 0.109, 0.122, 0.118, 0.116, 0.063, 0.113, 0.126, 0.126],
        backgroundColor: 'skyblue'
      },
      {
        label: 'GPT-4o',
        data: [0.240, 0.375, 0.365, 0.240, 0.009, 0.240, 0.009, 0.026, 0.181],
        backgroundColor: '#74AA9C'
      }
    ]
  };

  const config1 = {
    type: 'bar',
    data: data1,
    options: {
      responsive: true,
      plugins: {
        legend: { position: 'top' },
        title: { display: true, text: 'BAP vs LLMAO vs GPT-4o' }
      },
      scales: {
        x: {
          title: { display: true, text: 'Benchmark' }
        },
        y: {
          title: { display: true, text: 'Top-1 Accuracy' },
          min: 0.0,
          max: 0.6
        }
      }
    }
  };

  new Chart(ctx1, config1);
</script>

<!-- 2) MULTIPLE LINES PRECISION -->
<h2>Multiple Lines</h2>
<p>
  On multi-line bugs, BAP captures more relevant lines than typical single-line
  localizers, showing better precision at top-k lines.
</p>

<canvas id="barChart" width="800" height="600"></canvas>
<script>
  const ctx2 = document.getElementById('barChart').getContext('2d');

  const data2 = {
    labels: ['P@2', 'P@3', 'P@5'],
    datasets: [
      {
        label: 'Random',
        data: [0.201, 0.231, 0.297],
        backgroundColor: 'gray'
      },
      {
        label: 'CodeLlama-70B',
        data: [0.250, 0.284, 0.351],
        backgroundColor: 'skyblue'
      },
      {
        label: 'Llama-3.3-70B',
        data: [0.240, 0.266, 0.355],
        backgroundColor: 'royalblue'
      },
      {
        label: 'Qwen2.5-72B',
        data: [0.221, 0.271, 0.347],
        backgroundColor: 'SlateBlue'
      },
      {
        label: 'DeepSeek-R1-Distill-Llama-70B',
        data: [0.245, 0.283, 0.336],
        backgroundColor: '#4169E1'
      },
      {
        label: 'GPT-4o',
        data: [0.218, 0.288, 0.359],
        backgroundColor: '#74AA9C'
      },
      {
        label: 'BAP-Llama-3.2-11B',
        data: [0.289, 0.298, 0.367],
        backgroundColor: 'darkblue'
      }
    ]
  };

  const config2 = {
    type: 'bar',
    data: data2,
    options: {
      responsive: true,
      plugins: {
        legend: { position: 'top' },
        title: { display: true, text: 'Precision at Top-K Lines' }
      },
      scales: {
        x: { title: { display: true, text: 'Top-K Lines' } },
        y: {
          title: { display: true, text: 'Precision' },
          min: 0.15,
          max: 0.4
        }
      }
    }
  };

  new Chart(ctx2, config2);
</script>

<!-- 3) RESOURCE EFFICIENCY SCATTER -->
<h2>Resource Efficiency</h2>
<p>
  BAP’s smaller memory requirements and lower FLOPs mean it can be integrated
  into continuous integration workflows or potentially even local development
  IDEs.
</p>

<canvas id="scatterChart" width="800" height="600"></canvas>
<script>
  const ctx3 = document.getElementById('scatterChart').getContext('2d');

  const data3 = {
    datasets: [
      {
        label: 'BAP',
        data: [
          { x: 6.2,  y: 0.282, label: 'BAP-Llama-3.2-1B'  },
          { x: 24.2, y: 0.334, label: 'BAP-Llama-3.2-11B' }
        ],
        backgroundColor: 'royalblue',
        pointStyle: 'triangle',
        pointRadius: 9,
        borderColor: 'black',
        borderWidth: 1
      },
      {
        label: 'Zero-Shot',
        data: [
          { x: 170.0, y: 0.269, label: 'Llama-3.2-90B' },
          { x: 131.7, y: 0.212, label: 'CodeLlama-70B' },
          { x: 138.9, y: 0.157, label: 'Qwen2.5-72B' },
          { x: 154.0, y: 0.269, label: 'Llama-3.3-70B' },
          { x: 141.2, y: 0.221, label: 'DeepSeek-R1-Llama-3.3-70B' }
        ],
        backgroundColor: 'red',
        pointStyle: 'star',
        pointRadius: 8,
        borderColor: 'red',
        borderWidth: 2
      }
    ]
  };

  const config3 = {
    type: 'scatter',
    data: data3,
    options: {
      responsive: true,
      plugins: {
        legend: { position: 'top' },
        title: { display: true, text: 'Top-1 Accuracy vs GPU Cost' },
        tooltip: {
          callbacks: {
            label: function(context) {
              let dataPoint = context.raw;
              return `${dataPoint.label}: (${dataPoint.x}, ${dataPoint.y})`;
            }
          }
        }
      },
      scales: {
        x: { title: { display: true, text: 'GPU Cost (GB)' } },
        y: { title: { display: true, text: 'Top-1 Accuracy' } }
      }
    }
  };

  new Chart(ctx3, config3);
</script>
</body>
</html>

---

## Future Directions

- **Long-Code FL**: For functions spanning 100+ lines, BAP could be extended with different aggregation functions or improved attention mechanisms.  
- **Repository-Level Localization**: BAP currently focuses on method-level context; next steps involve bridging to entire files or multi-file projects.  
- **Broader Context**: Combining BAP with bug-fixing models or test generation frameworks might yield an end-to-end debugging pipeline.

---

## Conclusion

BAP demonstrates that weak supervision can yield strong line-level fault localization. It bridges the gap between requiring test-based FL and prompting large language models. If you’re searching for a simple, efficient, and performant way to spot code bugs, give BAP a look!

**Interested?**  
- **[Read the Paper](https://arxiv.org/abs/2502.13966)** for rigorous experiments, ablations, and theoretical underpinnings.  
- **[Check Out the Code](https://github.com/adaminsky/BAP)** to try BAP’s bug localization on your own projects.